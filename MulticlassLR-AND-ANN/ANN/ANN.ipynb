{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAME: DEEPESH BHATTA\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "(Artificial Neural Network, 30pts) For this part, you may use existing libraries (Yeah!). Implement an\n",
    "artificial neural network (ANN) by stacking up your perceptron. You may use one hidden layer and the\n",
    "number of hidden nodes are up to you. Use the same MNIST data as in P2 for training and testing. Try out\n",
    "both sigmoid and ReLU for activation functions. Print out accuracy, precision and recall at the end. Did\n",
    "the performance get better or worse compared to the result from P2? It can be either so justify your answer\n",
    "in your report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8-TSoTnF_vX",
    "outputId": "1d64f648-00cc-4b14-bb53-62868b3cd95a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Epoch 1/12\n",
      "469/469 [==============================] - 140s 299ms/step - loss: 2.2813 - accuracy: 0.1463 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.2467 - val_accuracy: 0.3089 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 140s 298ms/step - loss: 2.2249 - accuracy: 0.2622 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.1765 - val_accuracy: 0.5137 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 145s 309ms/step - loss: 2.1503 - accuracy: 0.3772 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 2.0786 - val_accuracy: 0.6100 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 141s 300ms/step - loss: 2.0452 - accuracy: 0.4642 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 1.9417 - val_accuracy: 0.6838 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 141s 300ms/step - loss: 1.9042 - accuracy: 0.5279 - precision: 0.0192 - recall: 1.5547e-04 - val_loss: 1.7602 - val_accuracy: 0.7339 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 141s 301ms/step - loss: 1.7289 - accuracy: 0.5715 - precision: 0.5217 - recall: 0.0076 - val_loss: 1.5394 - val_accuracy: 0.7671 - val_precision: 0.6962 - val_recall: 0.0141\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 142s 303ms/step - loss: 1.5323 - accuracy: 0.6108 - precision: 0.9609 - recall: 0.0519 - val_loss: 1.3090 - val_accuracy: 0.7864 - val_precision: 0.9987 - val_recall: 0.0837\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 145s 308ms/step - loss: 1.3514 - accuracy: 0.6385 - precision: 0.9439 - recall: 0.1458 - val_loss: 1.1091 - val_accuracy: 0.8007 - val_precision: 0.9917 - val_recall: 0.2443\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 141s 301ms/step - loss: 1.2026 - accuracy: 0.6644 - precision: 0.9194 - recall: 0.2586 - val_loss: 0.9529 - val_accuracy: 0.8131 - val_precision: 0.9852 - val_recall: 0.3820\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 141s 301ms/step - loss: 1.0878 - accuracy: 0.6831 - precision: 0.9044 - recall: 0.3607 - val_loss: 0.8380 - val_accuracy: 0.8229 - val_precision: 0.9740 - val_recall: 0.4877\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 141s 300ms/step - loss: 0.9988 - accuracy: 0.7034 - precision: 0.8923 - recall: 0.4358 - val_loss: 0.7521 - val_accuracy: 0.8300 - val_precision: 0.9682 - val_recall: 0.5705\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 145s 310ms/step - loss: 0.9306 - accuracy: 0.7193 - precision: 0.8846 - recall: 0.4929 - val_loss: 0.6877 - val_accuracy: 0.8385 - val_precision: 0.9621 - val_recall: 0.6279\n",
      "Test loss: 0.6877194046974182\n",
      "Test accuracy: 0.8385000228881836\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "def precision(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "def recall(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy', precision, recall])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "er0wqM8Nf4rq",
    "outputId": "a919a966-6c0d-4896-c1ca-dd6eb49b583a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy:  83.85000228881836 %\n",
      "PRECISION:  96.20188474655151 %\n",
      "RECALL:  62.72963285446167 %\n"
     ]
    }
   ],
   "source": [
    "print(' Accuracy: ', score[1]*100,\"%\")\n",
    "print('PRECISION: ', score[2]*100,\"%\" )\n",
    "print('RECALL: ', score[3]*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
